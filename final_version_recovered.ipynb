{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "integrated-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "from astropy.table import Table\n",
    "from astropy.cosmology import LambdaCDM as Cos\n",
    "from astropy.io import fits\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display \n",
    "from scipy import stats\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import norm\n",
    "import fitsio\n",
    "\n",
    "import pickle\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exclusive-carolina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:42767</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>9</li>\n",
       "  <li><b>Cores: </b>18</li>\n",
       "  <li><b>Memory: </b>67.31 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:42767' processes=9 threads=18, memory=67.31 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster(n_workers = 9)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "funded-bracket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load table of centers\n",
    "table_of_centers = pd.read_csv(\"local_table_of_centers.csv\")\n",
    "table_of_centers_south = table_of_centers[0:437]\n",
    "table_of_centers_north = table_of_centers[437:]\n",
    "clusters = []\n",
    "testing_centers = pd.read_csv(\"testing_sweeps2.csv\")\n",
    "#testing_centers = testing_centers[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-booking",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.seterr(divide = 'ignore', invalid = \"ignore\") \n",
    "#np.seterr(divide = 'warn', invalid = 'warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "offshore-geneva",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding neighboring sweeps\n",
    "nbrs = NearestNeighbors(n_neighbors=9, algorithm='ball_tree').fit(table_of_centers_south[[\"mean_RA\", \"mean_DEC\"]])\n",
    "\n",
    "#Mass fitting parameters and equations\n",
    "a = 1.3620186928378857  \n",
    "b = 9.968545069745126\n",
    "j= 1.04935943 \n",
    "k = 0.39573094 \n",
    "l = 0.28347756\n",
    "def mass_limit(z):\n",
    "    return np.minimum((a*z + b), 11.2)\n",
    "\n",
    "def mass_coefficient(z):\n",
    "    return np.exp(j*z**2 + k*z + l)\n",
    "\n",
    "#Radii\n",
    "radius = 1\n",
    "small_radius = 0.5\n",
    "mini_radius = 0.1\n",
    "\n",
    "#Buffer (in degrees, from interpolating maximum cluster radius at z = 0.05)\n",
    "buffer = 0.285"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sitting-barbados",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def data_import(maxx, maxy, minx, miny, row2):\n",
    "    fits_data = fitsio.FITS(row2.patch)\n",
    "    sweep = fits_data[1].read(columns=['RELEASE','BRICKID','BRICKNAME', 'OBJID', 'TYPE', 'RA', 'DEC', 'FLUX_G', 'FLUX_R', 'FLUX_Z', 'FLUX_W1', 'MASKBITS', 'GAIA_PHOT_G_MEAN_MAG', 'GAIA_ASTROMETRIC_EXCESS_NOISE'])\n",
    "    with fits.open(row2.photoz) as data:\n",
    "        pz = pd.DataFrame(data[1].data)\n",
    "    mass = np.load(row2.masses)\n",
    "    \n",
    "    pz['mass'] = mass\n",
    "    pz['RELEASE']=sweep['RELEASE']\n",
    "    pz['BRICKID']=sweep['BRICKID']\n",
    "    pz['BRICKNAME']=sweep['BRICKNAME']\n",
    "    pz['OBJID']=sweep['OBJID']\n",
    "    pz['TYPE']=sweep['TYPE']\n",
    "    pz['RA']=sweep['RA']\n",
    "    pz['DEC']=sweep['DEC']\n",
    "    pz['FLUX_G']=sweep['FLUX_G']\n",
    "    pz['FLUX_R']=sweep['FLUX_R']\n",
    "    pz['FLUX_Z']=sweep['FLUX_Z']\n",
    "    pz['FLUX_W1']=sweep['FLUX_W1']\n",
    "    pz['MASKBITS']=sweep['MASKBITS']\n",
    "    pz['gaia_phot_g_mean_mag']=sweep['GAIA_PHOT_G_MEAN_MAG']\n",
    "    pz['gaia_astrometric_excess_noise']=sweep['GAIA_ASTROMETRIC_EXCESS_NOISE']\n",
    "    pz = pz[np.logical_and.reduce((pz.RA < maxx + buffer/np.cos(pz.DEC*(np.pi/180)), pz.DEC < maxy + buffer, pz.RA > minx - buffer/np.cos(pz.DEC*(np.pi/180)), pz.DEC > miny - buffer))]\n",
    "    return pz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "modified-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@dask.delayed\n",
    "def cluster_finder(massive_sample, indexable, maxRA, maxDEC, minRA, minDEC):\n",
    "    #Cosmological Parameters: radius and cylinder length\n",
    "    cos = Cos(H0 = 70, Om0 = .286, Ode0 = .714)\n",
    "    z_array = np.linspace(1e-2, indexable[:, 0].max(), 500)\n",
    "    sparse_radius = (1+z_array)/(cos.comoving_distance(z_array))\n",
    "    radius_threshold = interp1d(z_array, sparse_radius, kind = \"linear\", fill_value = \"extrapolate\")\n",
    "    median = stats.binned_statistic(indexable[:, 0].astype(float), indexable[:, -1].astype(float), \"median\", bins = np.linspace(0.05, indexable[:, 0].max(), 100))\n",
    "    bins = np.linspace(0.05, indexable[:, 0].max(), 99)\n",
    "    z_threshold = interp1d(bins, np.minimum(median[0], np.ones(len(median[0]))*0.1), kind = \"linear\", fill_value = \"extrapolate\")\n",
    "    \n",
    "    #Tree Algorithm\n",
    "    iterrator = massive_sample.copy()\n",
    "    tree = spatial.cKDTree(indexable[:, 1:3].astype(float), copy_data = True)\n",
    "    for i, row in iterrator.iterrows():\n",
    "        neighbors = tree.query_ball_point([row.x, row.y], radius_threshold(row.z_phot_median))\n",
    "        if len(neighbors) > 0:\n",
    "            local_data = indexable[neighbors]\n",
    "            \n",
    "            z_c = z_threshold(row.z_phot_median)\n",
    "            cylinder = np.abs(np.vstack(local_data[:, 4]) - row.z_phot_median)\n",
    "            weight_array = cylinder < 2*z_c\n",
    "            weights = weight_array.sum(axis = 1)/oversample\n",
    "            \n",
    "            approx_cluster = np.append(local_data, np.reshape(weights, newshape = (len(weights), 1)), axis = 1)\n",
    "            cluster = approx_cluster[approx_cluster[:, -1] > 0]\n",
    "            \n",
    "            r_smaller = radius_threshold(row.z_phot_median)\n",
    "            small_cluster = cluster[np.sqrt(np.array((cluster[:, 1] - row.x)**2 + (cluster[:, 2] - row.y)**2).astype(float)) < 0.5*r_smaller]\n",
    "            mini_cluster = cluster[np.sqrt(np.array((cluster[:, 1] - row.x)**2 + (cluster[:, 2] - row.y)**2).astype(float)) < 0.1*r_smaller]\n",
    "            \n",
    "            massive_sample.at[i, \"z_average_no_wt\"] = np.mean(cluster[:, 0])\n",
    "            massive_sample.at[i, \"z_average_prob\"] = np.average(cluster[:, 0], weights = cluster[:, -1])\n",
    "            massive_sample.at[i, \"z_average_mass_prob\"] = np.average(cluster[:, 0], weights = cluster[:, -1]*cluster[:, 3])\n",
    "            \n",
    "            massive_sample.at[i, \"z_std_no_wt\"] = np.std(cluster[:, 0])\n",
    "            massive_sample.at[i, \"z_std_prob\"] = np.sqrt(np.cov(cluster[:, 0].astype(float), aweights = cluster[:, -1].astype(float)))\n",
    "            massive_sample.at[i, \"z_std_mass_prob\"] = np.sqrt(np.cov(cluster[:, 0].astype(float), aweights = cluster[:, -1]*cluster[:, 3].astype(float)))\n",
    "            \n",
    "            massive_sample.at[i, \"neighbors\"] = np.sum(cluster[:, -1])\n",
    "            massive_sample.at[i, \"local_neighbors\"] = np.sum(small_cluster[:, -1])\n",
    "            massive_sample.at[i, \"ultra_local_neighbors\"] = np.sum(mini_cluster[:, -1])\n",
    "            \n",
    "            mass_co = mass_coefficient(row.z_phot_median)\n",
    "            massive_sample.at[i, \"correction_factor\"] = mass_co\n",
    "            c_mask = cluster[:, 3]>mass_limit(row.z_phot_median)\n",
    "            cluster_limited = cluster[c_mask.astype(\"bool\"), :]\n",
    "            massive_sample.at[i, \"neighbor_mass\"] = np.log10(np.sum(np.append(((10**cluster_limited[:, 3]))*cluster_limited[:, -1], [10**row.mass]))*mass_co)\n",
    "            massive_sample.at[i, \"local_neighbor_mass\"] = np.log10(np.sum(np.append((10**small_cluster[:, 3])*small_cluster[:, -1], [10**row.mass])))\n",
    "            massive_sample.at[i, \"ultra_local_neighbor_mass\"] = np.log10(np.sum(np.append((10**mini_cluster[:, 3])*mini_cluster[:, -1], [10**row.mass])))\n",
    "            massive_sample.at[i, \"corr_local_neighbor_mass\"] = np.log10(np.sum(np.append((10**small_cluster[:, 3])*small_cluster[:, -1], [10**row.mass]))*mass_co)\n",
    "            massive_sample.at[i, \"corr_ultra_local_neighbor_mass\"] = np.log10(np.sum(np.append((10**mini_cluster[:, 3])*mini_cluster[:, -1], [10**row.mass]))*mass_co)\n",
    "            \n",
    "            clusterid = np.ones((1, len(local_data)))*row.gid\n",
    "            clusterz = np.ones((1, len(local_data)))*row.z_phot_median\n",
    "            membership = np.concatenate((local_data[:, -2].reshape((1, len(local_data))), clusterid, local_data[:, 0].reshape((1, len(local_data))), clusterz, local_data[:, -1].reshape((1, len(local_data)))), axis = 0).T\n",
    "            massive_sample.at[i, \"neighbor_gids\"] = membership\n",
    "            \n",
    "            \n",
    "    \n",
    "    #Thresholding\n",
    "    bins = np.arange(0.05, massive_sample.z_phot_median.max(), 0.01)\n",
    "    binned = [massive_sample[np.logical_and(massive_sample.z_phot_median>=i-.025, massive_sample.z_phot_median<=i+.025)].copy() for i in bins]\n",
    "    clusters = pd.DataFrame()\n",
    "    threshold1 = np.empty(len(binned))\n",
    "    threshold2 = np.empty(len(binned))\n",
    "    for i in range(len(binned)):\n",
    "        threshold1[i] = np.mean(binned[i].neighbors) + 1.8*np.sqrt(np.mean(binned[i].neighbors))\n",
    "        threshold2[i] = np.mean(binned[i].local_neighbors) + 1.2*np.sqrt(np.mean(binned[i].local_neighbors))\n",
    "    thresh1 = interp1d(bins, threshold1, kind = \"linear\", fill_value = \"extrapolate\")\n",
    "    thresh2 = interp1d(bins, threshold2, kind = \"linear\", fill_value = \"extrapolate\")\n",
    "    clusters = massive_sample[np.logical_and(massive_sample.neighbors >= thresh1(massive_sample.z_phot_median), massive_sample.local_neighbors >= thresh2(massive_sample.z_phot_median))].copy()\n",
    "    clusters.sort_values(\"local_neighbor_mass\", inplace = True, ascending = False)\n",
    "    clusters.reset_index(inplace= True, drop = True)\n",
    "    \n",
    "    #Aggregation\n",
    "    tree = spatial.cKDTree(clusters[[\"x\", \"y\"]], copy_data = True)\n",
    "    clusters[\"ncluster\"] = np.zeros(len(clusters))\n",
    "    clusternum = 1\n",
    "    iterrator2 = clusters.copy()\n",
    "    for i, row in iterrator2.iterrows():\n",
    "        if clusters.iloc[i].ncluster == 0:\n",
    "            clusters.at[i, \"ncluster\"] = clusternum\n",
    "            neighbors = tree.query_ball_point([row.x, row.y], 1.5*radius_threshold(row.z_phot_median))\n",
    "            for index in neighbors:\n",
    "                if np.logical_and(clusters.at[index, \"ncluster\"] == 0, np.abs(clusters.at[index, \"z_phot_median\"] - row.z_phot_median) < 2*z_threshold(row.z_phot_median)):\n",
    "                    clusters.at[index, \"ncluster\"] = clusternum\n",
    "                    clusters.at[i, \"neighbor_gids\"] = np.concatenate((clusters.at[i, \"neighbor_gids\"], clusters.at[index, \"neighbor_gids\"]), axis = 0) \n",
    "            clusternum += 1\n",
    "    \n",
    "    #Results\n",
    "    cluster_center = clusters.sort_values(by = ['ncluster','ultra_local_neighbor_mass'], ascending = [True, False]).groupby('ncluster').head(1).copy()\n",
    "    cluster_center_selected = cluster_center[np.logical_and.reduce((cluster_center.RA < maxRA, cluster_center.RA > minRA, cluster_center.DEC < maxDEC, cluster_center.DEC > minDEC))].copy()\n",
    "    \n",
    "    #Membership\n",
    "    membership = pd.DataFrame(cluster_center_selected.neighbor_gids.values)\n",
    "    membership_data = np.zeros((1, 5))\n",
    "    for i in range(0, len(membership)):\n",
    "        temp = np.stack(membership.values[i])[0]\n",
    "        membership_data = np.concatenate([membership_data, temp], axis = 0)\n",
    "    membershippd = pd.DataFrame(membership_data[1:], columns = [\"galaxy\", \"cluster\", \"galaxy_z\", \"cluster_z\", \"galaxy_z_std\"], dtype = float)\n",
    "    membershippd[\"z_dist\"] = np.abs(membershippd.galaxy_z - membershippd.cluster_z)\n",
    "    membershippd.sort_values(\"z_dist\", ascending = True, inplace = True)\n",
    "    membershippd.drop_duplicates(subset = \"galaxy\", inplace = True)\n",
    "    membershippd.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    iterrator3 = membershippd.copy()\n",
    "    membershippd[\"prob\"] = np.zeros(len(membershippd))\n",
    "    for i, row in iterrator3.iterrows():\n",
    "        x = row.galaxy_z\n",
    "        mu = row.cluster_z\n",
    "        std = row.galaxy_z_std\n",
    "        membershippd.at[i, \"prob\"] = 2*(1-norm.cdf(x = np.abs(x-mu), loc = 0, scale = std))\n",
    "    memberspd = membershippd[membershippd.prob > 0.0027].astype({\"galaxy\": \"int64\", \"cluster\": \"int64\"}).drop(columns = {\"z_dist\"})\n",
    "    \n",
    "    #Cleaning things up\n",
    "    cluster_center_selected[\"BRICKNAME\"] = cluster_center_selected[\"BRICKNAME\"].astype('|S80')\n",
    "    clusters_final = cluster_center_selected[[\"RA\", \"DEC\", \"z_phot_median\", \"z_average_no_wt\", \"z_average_prob\", \"z_average_mass_prob\", \"z_phot_std\", \"z_std_no_wt\", \"z_std_prob\", \"z_std_mass_prob\", \"RELEASE\", \"BRICKID\", \"OBJID\", \"MASKBITS\", \"gid\", \"mass\", \"neighbor_mass\", \"corr_local_neighbor_mass\", \"corr_ultra_local_neighbor_mass\", \"correction_factor\", \"neighbors\", \"local_neighbors\", \"ultra_local_neighbors\"]].copy()\n",
    "    clusters_final.columns = [\"RA_central\", \"DEC_central\", \"z_median_central\", \"z_average_no_wt\", \"z_average_prob\", \"z_average_mass_prob\", \"z_std_central\", \"z_std_no_wt\", \"z_std_prob\", \"z_std_mass_prob\", \"RELEASE\", \"BRICKID\", \"OBJID\", \"MASKBITS\", \"gid\", \"mass_central\", \"neighbor_mass\", \"local_neighbor_mass\", \"ultra_local_neighbor_mass\", \"correction_factor\", \"neighbors\", \"local_neighbors\", \"ultra_local_neighbors\"]\n",
    "    \n",
    "    return clusters_final, memberspd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bored-bradley",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>patch</th>\n",
       "      <th>mean_RA</th>\n",
       "      <th>mean_DEC</th>\n",
       "      <th>photoz</th>\n",
       "      <th>masses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>/data/mjb299/sweep/sweep-190p030-200p035.fits</td>\n",
       "      <td>195.206692</td>\n",
       "      <td>31.979525</td>\n",
       "      <td>/data/mjb299/pz/sweep-190p030-200p035-pz.fits</td>\n",
       "      <td>/data/mjb299/pz/sweep-190p030-200p035_stellar_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>92.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>/data/mjb299/sweep/sweep-170p025-180p030.fits</td>\n",
       "      <td>175.036076</td>\n",
       "      <td>27.486449</td>\n",
       "      <td>/data/mjb299/pz/sweep-170p025-180p030-pz.fits</td>\n",
       "      <td>/data/mjb299/pz/sweep-170p025-180p030_stellar_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>216.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>/data/mjb299/sweep/sweep-180p030-190p035.fits</td>\n",
       "      <td>184.901037</td>\n",
       "      <td>32.099699</td>\n",
       "      <td>/data/mjb299/pz/sweep-180p030-190p035-pz.fits</td>\n",
       "      <td>/data/mjb299/pz/sweep-180p030-190p035_stellar_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>/data/mjb299/sweep/sweep-180p025-190p030.fits</td>\n",
       "      <td>184.882132</td>\n",
       "      <td>27.488065</td>\n",
       "      <td>/data/mjb299/pz/sweep-180p025-190p030-pz.fits</td>\n",
       "      <td>/data/mjb299/pz/sweep-180p025-190p030_stellar_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>316.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>/data/mjb299/sweep/sweep-170p030-180p035.fits</td>\n",
       "      <td>175.040271</td>\n",
       "      <td>32.140876</td>\n",
       "      <td>/data/mjb299/pz/sweep-170p030-180p035-pz.fits</td>\n",
       "      <td>/data/mjb299/pz/sweep-170p030-180p035_stellar_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>394.0</td>\n",
       "      <td>394.0</td>\n",
       "      <td>/data/mjb299/sweep/sweep-190p025-200p030.fits</td>\n",
       "      <td>194.986337</td>\n",
       "      <td>27.503652</td>\n",
       "      <td>/data/mjb299/pz/sweep-190p025-200p030-pz.fits</td>\n",
       "      <td>/data/mjb299/pz/sweep-190p025-200p030_stellar_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>467.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>/data/mjb299/sweep-north/sweep-190p030-200p035...</td>\n",
       "      <td>194.931985</td>\n",
       "      <td>33.023176</td>\n",
       "      <td>/data/mjb299/pz-north/sweep-190p030-200p035-pz...</td>\n",
       "      <td>/data/mjb299/pz-north/sweep-190p030-200p035_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>496.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>/data/mjb299/sweep-north/sweep-170p025-180p030...</td>\n",
       "      <td>174.629494</td>\n",
       "      <td>29.651472</td>\n",
       "      <td>/data/mjb299/pz-north/sweep-170p025-180p030-pz...</td>\n",
       "      <td>/data/mjb299/pz-north/sweep-170p025-180p030_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>573.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>/data/mjb299/sweep-north/sweep-180p030-190p035...</td>\n",
       "      <td>184.932171</td>\n",
       "      <td>32.894182</td>\n",
       "      <td>/data/mjb299/pz-north/sweep-180p030-190p035-pz...</td>\n",
       "      <td>/data/mjb299/pz-north/sweep-180p030-190p035_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>631.0</td>\n",
       "      <td>631.0</td>\n",
       "      <td>/data/mjb299/sweep-north/sweep-180p025-190p030...</td>\n",
       "      <td>184.702577</td>\n",
       "      <td>29.640620</td>\n",
       "      <td>/data/mjb299/pz-north/sweep-180p025-190p030-pz...</td>\n",
       "      <td>/data/mjb299/pz-north/sweep-180p025-190p030_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>646.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>/data/mjb299/sweep-north/sweep-170p030-180p035...</td>\n",
       "      <td>175.078591</td>\n",
       "      <td>32.875770</td>\n",
       "      <td>/data/mjb299/pz-north/sweep-170p030-180p035-pz...</td>\n",
       "      <td>/data/mjb299/pz-north/sweep-170p030-180p035_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>696.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>/data/mjb299/sweep-north/sweep-190p025-200p030...</td>\n",
       "      <td>194.149887</td>\n",
       "      <td>29.659346</td>\n",
       "      <td>/data/mjb299/pz-north/sweep-190p025-200p030-pz...</td>\n",
       "      <td>/data/mjb299/pz-north/sweep-190p025-200p030_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/data/mjb299/sweep/sweep-000m005-010p000.fits</td>\n",
       "      <td>5.027669</td>\n",
       "      <td>-2.508936</td>\n",
       "      <td>/data/mjb299/pz/sweep-000m005-010p000-pz.fits</td>\n",
       "      <td>/data/mjb299/pz/sweep-000m005-010p000_stellar_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  \\\n",
       "0            0          42.0            42.0   \n",
       "1            1          92.0            92.0   \n",
       "2            2         216.0           216.0   \n",
       "3            3         300.0           300.0   \n",
       "4            4         316.0           316.0   \n",
       "5            5         394.0           394.0   \n",
       "6            6         467.0           467.0   \n",
       "7            7         496.0           496.0   \n",
       "8            8         573.0           573.0   \n",
       "9            9         631.0           631.0   \n",
       "10          10         646.0           646.0   \n",
       "11          11         696.0           696.0   \n",
       "12          12           0.0             0.0   \n",
       "\n",
       "                                                patch     mean_RA   mean_DEC  \\\n",
       "0       /data/mjb299/sweep/sweep-190p030-200p035.fits  195.206692  31.979525   \n",
       "1       /data/mjb299/sweep/sweep-170p025-180p030.fits  175.036076  27.486449   \n",
       "2       /data/mjb299/sweep/sweep-180p030-190p035.fits  184.901037  32.099699   \n",
       "3       /data/mjb299/sweep/sweep-180p025-190p030.fits  184.882132  27.488065   \n",
       "4       /data/mjb299/sweep/sweep-170p030-180p035.fits  175.040271  32.140876   \n",
       "5       /data/mjb299/sweep/sweep-190p025-200p030.fits  194.986337  27.503652   \n",
       "6   /data/mjb299/sweep-north/sweep-190p030-200p035...  194.931985  33.023176   \n",
       "7   /data/mjb299/sweep-north/sweep-170p025-180p030...  174.629494  29.651472   \n",
       "8   /data/mjb299/sweep-north/sweep-180p030-190p035...  184.932171  32.894182   \n",
       "9   /data/mjb299/sweep-north/sweep-180p025-190p030...  184.702577  29.640620   \n",
       "10  /data/mjb299/sweep-north/sweep-170p030-180p035...  175.078591  32.875770   \n",
       "11  /data/mjb299/sweep-north/sweep-190p025-200p030...  194.149887  29.659346   \n",
       "12      /data/mjb299/sweep/sweep-000m005-010p000.fits    5.027669  -2.508936   \n",
       "\n",
       "                                               photoz  \\\n",
       "0       /data/mjb299/pz/sweep-190p030-200p035-pz.fits   \n",
       "1       /data/mjb299/pz/sweep-170p025-180p030-pz.fits   \n",
       "2       /data/mjb299/pz/sweep-180p030-190p035-pz.fits   \n",
       "3       /data/mjb299/pz/sweep-180p025-190p030-pz.fits   \n",
       "4       /data/mjb299/pz/sweep-170p030-180p035-pz.fits   \n",
       "5       /data/mjb299/pz/sweep-190p025-200p030-pz.fits   \n",
       "6   /data/mjb299/pz-north/sweep-190p030-200p035-pz...   \n",
       "7   /data/mjb299/pz-north/sweep-170p025-180p030-pz...   \n",
       "8   /data/mjb299/pz-north/sweep-180p030-190p035-pz...   \n",
       "9   /data/mjb299/pz-north/sweep-180p025-190p030-pz...   \n",
       "10  /data/mjb299/pz-north/sweep-170p030-180p035-pz...   \n",
       "11  /data/mjb299/pz-north/sweep-190p025-200p030-pz...   \n",
       "12      /data/mjb299/pz/sweep-000m005-010p000-pz.fits   \n",
       "\n",
       "                                               masses  \n",
       "0   /data/mjb299/pz/sweep-190p030-200p035_stellar_...  \n",
       "1   /data/mjb299/pz/sweep-170p025-180p030_stellar_...  \n",
       "2   /data/mjb299/pz/sweep-180p030-190p035_stellar_...  \n",
       "3   /data/mjb299/pz/sweep-180p025-190p030_stellar_...  \n",
       "4   /data/mjb299/pz/sweep-170p030-180p035_stellar_...  \n",
       "5   /data/mjb299/pz/sweep-190p025-200p030_stellar_...  \n",
       "6   /data/mjb299/pz-north/sweep-190p030-200p035_st...  \n",
       "7   /data/mjb299/pz-north/sweep-170p025-180p030_st...  \n",
       "8   /data/mjb299/pz-north/sweep-180p030-190p035_st...  \n",
       "9   /data/mjb299/pz-north/sweep-180p025-190p030_st...  \n",
       "10  /data/mjb299/pz-north/sweep-170p030-180p035_st...  \n",
       "11  /data/mjb299/pz-north/sweep-190p025-200p030_st...  \n",
       "12  /data/mjb299/pz/sweep-000m005-010p000_stellar_...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "chubby-turkey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<progress style='width:60ex' max='13' value='0'></progress>"
      ],
      "text/plain": [
       "[                                                            ] 0/13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5522115\n",
      "     Unnamed: 0                                          patch    mean_RA  \\\n",
      "22           22  /data/mjb299/sweep/sweep-000m005-010p000.fits   5.027669   \n",
      "362         362  /data/mjb299/sweep/sweep-000m010-010m005.fits   4.998628   \n",
      "126         126  /data/mjb299/sweep/sweep-000p000-010p005.fits   4.974314   \n",
      "32           32  /data/mjb299/sweep/sweep-000m015-010m010.fits   5.126173   \n",
      "379         379  /data/mjb299/sweep/sweep-000p005-010p010.fits   5.039875   \n",
      "314         314  /data/mjb299/sweep/sweep-010m005-020p000.fits  14.970043   \n",
      "382         382  /data/mjb299/sweep/sweep-010m010-020m005.fits  15.011904   \n",
      "238         238  /data/mjb299/sweep/sweep-010p000-020p005.fits  14.979433   \n",
      "100         100  /data/mjb299/sweep/sweep-010p005-020p010.fits  15.009611   \n",
      "\n",
      "      mean_DEC                                         photoz  \\\n",
      "22   -2.508936  /data/mjb299/pz/sweep-000m005-010p000-pz.fits   \n",
      "362  -7.250919  /data/mjb299/pz/sweep-000m010-010m005-pz.fits   \n",
      "126   2.421131  /data/mjb299/pz/sweep-000p000-010p005-pz.fits   \n",
      "32  -12.380325  /data/mjb299/pz/sweep-000m015-010m010-pz.fits   \n",
      "379   7.427670  /data/mjb299/pz/sweep-000p005-010p010-pz.fits   \n",
      "314  -2.452641  /data/mjb299/pz/sweep-010m005-020p000-pz.fits   \n",
      "382  -7.288320  /data/mjb299/pz/sweep-010m010-020m005-pz.fits   \n",
      "238   2.434296  /data/mjb299/pz/sweep-010p000-020p005-pz.fits   \n",
      "100   7.441656  /data/mjb299/pz/sweep-010p005-020p010-pz.fits   \n",
      "\n",
      "                                                masses  \n",
      "22   /data/mjb299/pz/sweep-000m005-010p000_stellar_...  \n",
      "362  /data/mjb299/pz/sweep-000m010-010m005_stellar_...  \n",
      "126  /data/mjb299/pz/sweep-000p000-010p005_stellar_...  \n",
      "32   /data/mjb299/pz/sweep-000m015-010m010_stellar_...  \n",
      "379  /data/mjb299/pz/sweep-000p005-010p010_stellar_...  \n",
      "314  /data/mjb299/pz/sweep-010m005-020p000_stellar_...  \n",
      "382  /data/mjb299/pz/sweep-010m010-020m005_stellar_...  \n",
      "238  /data/mjb299/pz/sweep-010p000-020p005_stellar_...  \n",
      "100  /data/mjb299/pz/sweep-010p005-020p010_stellar_...  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-157f6ca13baa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mlist_of_imports\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed_import\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mimports\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlist_of_imports\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mra_dec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimports\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mra_dec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0mpostcomputes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, dsk, keys, workers, allow_other_workers, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\u001b[0m\n\u001b[1;32m   2652\u001b[0m                     \u001b[0mshould_rejoin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2654\u001b[0;31m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2655\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   1967\u001b[0m                 \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m                 \u001b[0mlocal_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1969\u001b[0;31m                 \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1970\u001b[0m             )\n\u001b[1;32m   1971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/distributed/client.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    836\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             return sync(\n\u001b[0;32m--> 838\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m             )\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n"
     ]
    }
   ],
   "source": [
    "pbar = display.ProgressBar(len(testing_centers))\n",
    "pbar.display()\n",
    "\n",
    "delayed_results = []\n",
    "\n",
    "#Remember to change testing_centers to table_of_centers\n",
    "for index, row in testing_centers[0:1].iterrows():\n",
    "    fits_data = fitsio.FITS(row.patch)\n",
    "    sweep = fits_data[1].read(columns=['RA', 'DEC'])\n",
    "    print(len(sweep))\n",
    "    maxx = max(sweep['RA'])\n",
    "    maxy = max(sweep['DEC'])\n",
    "    minx = min(sweep['RA'])\n",
    "    miny = min(sweep['DEC'])\n",
    "    \n",
    "    maxRA = max(sweep['RA'])\n",
    "    maxDEC = max(sweep['DEC'])\n",
    "    minRA = min(sweep['RA'])\n",
    "    minDEC = min(sweep['DEC'])\n",
    "    \n",
    "    list_of_imports = []\n",
    "    #Neighbors:\n",
    "    distances, indices = nbrs.kneighbors([row[[\"mean_RA\", \"mean_DEC\"]]])\n",
    "    patches = table_of_centers_south.iloc[indices[0]]\n",
    "    print(patches)\n",
    "    for index2, row2 in patches.iterrows():\n",
    "        delayed_import = data_import(maxx, maxy, minx, miny, row2)\n",
    "        list_of_imports.append(delayed_import)\n",
    "    \n",
    "    imports = dask.compute(*list_of_imports)\n",
    "    ra_dec = pd.concat(imports)\n",
    "    print(len(ra_dec))\n",
    "    #Initial sample cuts\n",
    "    zmag=np.array(22.5-2.5*np.log10(ra_dec.FLUX_Z))\n",
    "    zmag[np.where(~np.isfinite(zmag))]=99.\n",
    "    #whgood=np.where(np.logical_and(zmag < 21,ra_dec.mass > 0 ))\n",
    "    isgood=np.logical_and(zmag < 21,ra_dec.mass > 0 )\n",
    "    ra_dec = ra_dec[isgood]\n",
    "    print(len(ra_dec))\n",
    "    \n",
    "    #Further sample cuts\n",
    "    ra_dec = ra_dec[np.logical_or(ra_dec.MASKBITS == 0, ra_dec.MASKBITS == 4096)]\n",
    "    ra_dec = ra_dec[np.logical_or(np.logical_or(ra_dec.gaia_phot_g_mean_mag > 19, ra_dec.gaia_astrometric_excess_noise > 10**.5), ra_dec.gaia_astrometric_excess_noise==0)]\n",
    "    ra_dec[\"magR\"] = 22.5-2.5*np.log10(ra_dec.FLUX_R)\n",
    "    ra_dec[\"magZ\"] = 22.5-2.5*np.log10(ra_dec.FLUX_Z)\n",
    "    ra_dec[\"magW1\"] = 22.5-2.5*np.log10(ra_dec.FLUX_W1)\n",
    "    l_mask = (ra_dec.magR - ra_dec.magW1) > 1.8*(ra_dec.magR-ra_dec.magZ)-0.6\n",
    "    l_mask[~np.isfinite(l_mask)] = False\n",
    "    ra_dec = ra_dec[np.logical_and(22.5 - 2.5*np.log10(ra_dec.FLUX_Z)<21, ra_dec.z_phot_median>0.01)]\n",
    "    \n",
    "    #Coordinates\n",
    "    ra_dec[\"RA_r\"] = (np.pi/180)*ra_dec[\"RA\"]\n",
    "    ra_dec[\"DEC_r\"] = (np.pi/180)*ra_dec[\"DEC\"]\n",
    "    ra_dec[\"gid\"] = np.round(ra_dec.RA, 6)*10**16 + np.round(ra_dec.DEC + 90, 6)*10**6\n",
    "    \n",
    "    #Oversampling\n",
    "    ra_dec.reset_index(inplace = True, drop = True)\n",
    "    oversample = 30\n",
    "    over = np.array([ra_dec.z_phot_median.values]).T*np.ones((len(ra_dec), oversample))\n",
    "    sigma = np.array([ra_dec.z_phot_std.values]).T*np.ones((len(ra_dec), oversample))\n",
    "    random = np.random.normal(loc = 0, scale = 1, size = (len(ra_dec), oversample))\n",
    "    gauss = over + sigma*random\n",
    "    ra_dec[\"gauss_z\"] = pd.Series(list(gauss))\n",
    "    \n",
    "    #Coordinate transform to prevent zeros\n",
    "    ra_dec[\"y\"] = ra_dec[\"DEC_r\"] - np.mean(ra_dec[\"DEC_r\"]) + 50\n",
    "    ra_dec[\"x\"] = (ra_dec[\"RA_r\"] - np.mean(ra_dec[\"RA_r\"]))*np.cos(ra_dec[\"DEC_r\"]) + 50\n",
    "    #ra_dec = ra_dec[ra_dec.z_phot_median < 1.5].copy()\n",
    "    #Creating array for indexing\n",
    "    indexable = ra_dec[[\"z_phot_median\", \"x\", \"y\", \"mass\", \"gauss_z\", \"gid\", \"z_phot_std\"]].values.copy()\n",
    "    \n",
    "    #Creating massive sample\n",
    "    massive_sample = ra_dec[ra_dec.mass > 11.2].copy()\n",
    "    massive_sample[\"neighbor_mass\"] = np.zeros(len(massive_sample))\n",
    "    massive_sample[\"local_neighbor_mass\"] = np.zeros(len(massive_sample))\n",
    "    massive_sample[\"ultra_local_neighbor_mass\"] = np.zeros(len(massive_sample))\n",
    "    massive_sample[\"corrected_neighbor_mass\"] = np.zeros(len(massive_sample))\n",
    "    massive_sample[\"neighbors\"] = np.zeros(len(massive_sample))\n",
    "    massive_sample[\"local_neighbors\"] = np.zeros(len(massive_sample))\n",
    "    massive_sample[\"ultra_local_neighbors\"] = np.zeros(len(massive_sample))\n",
    "    massive_sample[\"neighbor_gids\"] = np.empty((len(massive_sample)), dtype = \"object\")\n",
    "    massive_sample[\"z_average_no_wt\"] = np.zeros(len(massive_sample))\n",
    "    massive_sample[\"z_average_prob\"] = np.zeros(len(massive_sample))\n",
    "    massive_sample[\"z_average_mass_prob\"] = np.zeros(len(massive_sample))\n",
    "    massive_sample[\"z_std_no_wt\"] = np.zeros(len(massive_sample))\n",
    "    massive_sample[\"z_std_prob\"] = np.zeros(len(massive_sample))\n",
    "    massive_sample[\"z_std_mass_prob\"] = np.zeros(len(massive_sample))\n",
    "    massive_sample.reset_index(inplace=True, drop = True)\n",
    "    \n",
    "    delayed_result, _ = cluster_finder(massive_sample, indexable, maxRA, maxDEC, minRA, minDEC)\n",
    "    print(len(delayed_result))\n",
    "    \"\"\"delayed_results.append(delayed_result)\n",
    "    \n",
    "    if (index)%3 == 0:\n",
    "        results = dask.compute(*delayed_results)\n",
    "        if len(results)>1:\n",
    "            cluster_centrals = pd.concat([select[0] for select in results])\n",
    "            cluster_members = pd.concat([select[1] for select in results])\n",
    "        else:\n",
    "            cluster_centrals = results[0][0]\n",
    "            cluster_members = results[0][1]\n",
    "        print(len(cluster_centrals), len(cluster_members))\n",
    "        cc = Table.from_pandas(cluster_centrals)\n",
    "        cm = Table.from_pandas(cluster_members)\n",
    "        cc.write(f'test_table_c{index}.fits', format = 'fits')\n",
    "        cm.write(f'test_table_m{index}.fits', format = 'fits')\n",
    "        delayed_results = []\n",
    "    \n",
    "    if index+1 == len(testing_centers):\n",
    "        results = dask.compute(*delayed_results)\n",
    "        if len(results)>1:\n",
    "            cluster_centrals = pd.concat([select[0] for select in results])\n",
    "            cluster_members = pd.concat([select[1] for select in results])\n",
    "        else:\n",
    "            cluster_centrals = results[0][0]\n",
    "            cluster_members = results[0][1]\n",
    "        print(len(cluster_centrals), len(cluster_members))\n",
    "        cc = Table.from_pandas(cluster_centrals)\n",
    "        cm = Table.from_pandas(cluster_members)\n",
    "        cc.write(f'test_table_c{index}.fits', format = 'fits')\n",
    "        cm.write(f'test_table_m{index}.fits', format = 'fits')\n",
    "    \n",
    "    pbar.progress = index + 1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-rover",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @@ Cell 1\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "from astropy.table import Table\n",
    "from astropy.cosmology import LambdaCDM as Cos\n",
    "from astropy.io import fits\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display \n",
    "from scipy import stats\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import norm\n",
    "import fitsio\n",
    "\n",
    "import pickle\n",
    "import dask\n",
    "\n",
    "# @@ Cell 2\n",
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster(n_workers = 9)\n",
    "client = Client(cluster)\n",
    "client\n",
    "\n",
    "# @@ Cell 3\n",
    "# load table of centers\n",
    "table_of_centers = pd.read_csv(\"local_table_of_centers.csv\")\n",
    "table_of_centers_south = table_of_centers[0:437]\n",
    "table_of_centers_north = table_of_centers[437:]\n",
    "clusters = []\n",
    "testing_centers = pd.read_csv(\"testing_sweeps2.csv\")\n",
    "#testing_centers = testing_centers[0:1]\n",
    "\n",
    "# @@ Cell 4\n",
    "len(testing_centers)\n",
    "\n",
    "# @@ Cell 5\n",
    "#np.seterr(divide = 'ignore', invalid = \"ignore\") \n",
    "#np.seterr(divide = 'warn', invalid = 'warn')\n",
    "\n",
    "# @@ Cell 6\n",
    "nbrs = NearestNeighbors(n_neighbors=9, algorithm='ball_tree').fit(table_of_centers_south[[\"mean_RA\", \"mean_DEC\"]])\n",
    "\n",
    "# @@ Cell 7\n",
    "#Mass fitting parameters and equations\n",
    "a = 1.3620186928378857  \n",
    "b = 9.968545069745126\n",
    "j= 1.04935943 \n",
    "k = 0.39573094 \n",
    "l = 0.28347756\n",
    "def mass_limit(z):\n",
    "    return np.minimum((a*z + b), 11.2)\n",
    "\n",
    "def mass_coefficient(z):\n",
    "    return np.exp(j*z**2 + k*z + l)\n",
    "\n",
    "# @@ Cell 8\n",
    "#Radii\n",
    "radius = 1\n",
    "small_radius = 0.5\n",
    "mini_radius = 0.1\n",
    "\n",
    "\n",
    "\n",
    "# @@ Cell 10\n",
    "@dask.delayed\n",
    "def cluster_finder(massive_sample, indexable, maxRA, maxDEC, minRA, minDEC):\n",
    "    \n",
    "    #Cosmological Parameters: radius and cylinder length\n",
    "    cos = Cos(H0 = 70, Om0 = .286, Ode0 = .714)\n",
    "    z_array = np.linspace(1e-2, indexable[:, 0].max(), 500)\n",
    "    sparse_radius = (1+z_array)/(cos.comoving_distance(z_array))\n",
    "    radius_threshold = interp1d(z_array, sparse_radius, kind = \"linear\", fill_value = \"extrapolate\")\n",
    "    median = stats.binned_statistic(indexable[:, 0].astype(float), indexable[:, -1].astype(float), \"median\", bins = np.linspace(0.05, indexable[:, 0].max(), 100))\n",
    "    bins = np.linspace(0.05, indexable[:, 0].max(), 99)\n",
    "    z_threshold = interp1d(bins, np.minimum(median[0], np.ones(len(median[0]))*0.1), kind = \"linear\", fill_value = \"extrapolate\")\n",
    "    \n",
    "    #Tree Algorithm\n",
    "    iterrator = massive_sample.copy()\n",
    "    tree = spatial.cKDTree(indexable[:, 1:3].astype(float), copy_data = True)\n",
    "    for i, row in iterrator.iterrows():\n",
    "        neighbors = tree.query_ball_point([row.x, row.y], radius_threshold(row.z_phot_median))\n",
    "        if len(neighbors) > 0:\n",
    "            local_data = indexable[neighbors]\n",
    "            \n",
    "            z_c = z_threshold(row.z_phot_median)\n",
    "            cylinder = np.abs(np.vstack(local_data[:, 4]) - row.z_phot_median)\n",
    "            weight_array = cylinder < 2*z_c\n",
    "            weights = weight_array.sum(axis = 1)/oversample\n",
    "            \n",
    "            approx_cluster = np.append(local_data, np.reshape(weights, newshape = (len(weights), 1)), axis = 1)\n",
    "            cluster = approx_cluster[approx_cluster[:, -1] > 0]\n",
    "            \n",
    "            r_smaller = radius_threshold(row.z_phot_median)\n",
    "            small_cluster = cluster[np.sqrt(np.array((cluster[:, 1] - row.x)**2 + (cluster[:, 2] - row.y)**2).astype(float)) < 0.5*r_smaller]\n",
    "            mini_cluster = cluster[np.sqrt(np.array((cluster[:, 1] - row.x)**2 + (cluster[:, 2] - row.y)**2).astype(float)) < 0.1*r_smaller]\n",
    "            \n",
    "            massive_sample.at[i, \"z_average_no_wt\"] = np.mean(cluster[:, 0])\n",
    "            massive_sample.at[i, \"z_average_prob\"] = np.average(cluster[:, 0], weights = cluster[:, -1])\n",
    "            massive_sample.at[i, \"z_average_mass_prob\"] = np.average(cluster[:, 0], weights = cluster[:, -1]*cluster[:, 3])\n",
    "            \n",
    "            massive_sample.at[i, \"z_std_no_wt\"] = np.std(cluster[:, 0])\n",
    "            massive_sample.at[i, \"z_std_prob\"] = np.sqrt(np.cov(cluster[:, 0].astype(float), aweights = cluster[:, -1].astype(float)))\n",
    "            massive_sample.at[i, \"z_std_mass_prob\"] = np.sqrt(np.cov(cluster[:, 0].astype(float), aweights = cluster[:, -1]*cluster[:, 3].astype(float)))\n",
    "            \n",
    "            massive_sample.at[i, \"neighbors\"] = np.sum(cluster[:, -1])\n",
    "            massive_sample.at[i, \"local_neighbors\"] = np.sum(small_cluster[:, -1])\n",
    "            massive_sample.at[i, \"ultra_local_neighbors\"] = np.sum(mini_cluster[:, -1])\n",
    "            \n",
    "            mass_co = mass_coefficient(row.z_phot_median)\n",
    "            massive_sample.at[i, \"correction_factor\"] = mass_co\n",
    "            c_mask = cluster[:, 3]>mass_limit(row.z_phot_median)\n",
    "            cluster_limited = cluster[c_mask.astype(\"bool\"), :]\n",
    "            massive_sample.at[i, \"neighbor_mass\"] = np.log10(np.sum(np.append(((10**cluster_limited[:, 3]))*cluster_limited[:, -1], [10**row.mass]))*mass_co)\n",
    "            massive_sample.at[i, \"local_neighbor_mass\"] = np.log10(np.sum(np.append((10**small_cluster[:, 3])*small_cluster[:, -1], [10**row.mass])))\n",
    "            massive_sample.at[i, \"ultra_local_neighbor_mass\"] = np.log10(np.sum(np.append((10**mini_cluster[:, 3])*mini_cluster[:, -1], [10**row.mass])))\n",
    "            massive_sample.at[i, \"corr_local_neighbor_mass\"] = np.log10(np.sum(np.append((10**small_cluster[:, 3])*small_cluster[:, -1], [10**row.mass]))*mass_co)\n",
    "            massive_sample.at[i, \"corr_ultra_local_neighbor_mass\"] = np.log10(np.sum(np.append((10**mini_cluster[:, 3])*mini_cluster[:, -1], [10**row.mass]))*mass_co)\n",
    "            \n",
    "            clusterid = np.ones((1, len(local_data)))*row.gid\n",
    "            clusterz = np.ones((1, len(local_data)))*row.z_phot_median\n",
    "            membership = np.concatenate((local_data[:, -2].reshape((1, len(local_data))), clusterid, local_data[:, 0].reshape((1, len(local_data))), clusterz, local_data[:, -1].reshape((1, len(local_data)))), axis = 0).T\n",
    "            massive_sample.at[i, \"neighbor_gids\"] = membership\n",
    "            \n",
    "            \n",
    "    \n",
    "    #Thresholding\n",
    "    bins = np.arange(0.05, massive_sample.z_phot_median.max(), 0.01)\n",
    "    binned = [massive_sample[np.logical_and(massive_sample.z_phot_median>=i-.025, massive_sample.z_phot_median<=i+.025)].copy() for i in bins]\n",
    "    clusters = pd.DataFrame()\n",
    "    threshold1 = np.empty(len(binned))\n",
    "    threshold2 = np.empty(len(binned))\n",
    "    for i in range(len(binned)):\n",
    "        threshold1[i] = np.mean(binned[i].neighbors) + 1.8*np.sqrt(np.mean(binned[i].neighbors))\n",
    "        threshold2[i] = np.mean(binned[i].local_neighbors) + 1.2*np.sqrt(np.mean(binned[i].local_neighbors))\n",
    "    thresh1 = interp1d(bins, threshold1, kind = \"linear\", fill_value = \"extrapolate\")\n",
    "    thresh2 = interp1d(bins, threshold2, kind = \"linear\", fill_value = \"extrapolate\")\n",
    "    clusters = massive_sample[np.logical_and(massive_sample.neighbors >= thresh1(massive_sample.z_phot_median), massive_sample.local_neighbors >= thresh2(massive_sample.z_phot_median))].copy()\n",
    "    clusters.sort_values(\"local_neighbor_mass\", inplace = True, ascending = False)\n",
    "    clusters.reset_index(inplace= True, drop = True)\n",
    "    \n",
    "    #Aggregation\n",
    "    tree = spatial.cKDTree(clusters[[\"x\", \"y\"]], copy_data = True)\n",
    "    clusters[\"ncluster\"] = np.zeros(len(clusters))\n",
    "    clusternum = 1\n",
    "    iterrator2 = clusters.copy()\n",
    "    for i, row in iterrator2.iterrows():\n",
    "        if clusters.iloc[i].ncluster == 0:\n",
    "            clusters.at[i, \"ncluster\"] = clusternum\n",
    "            neighbors = tree.query_ball_point([row.x, row.y], 1.5*radius_threshold(row.z_phot_median))\n",
    "            for index in neighbors:\n",
    "                if np.logical_and(clusters.at[index, \"ncluster\"] == 0, np.abs(clusters.at[index, \"z_phot_median\"] - row.z_phot_median) < 2*z_threshold(row.z_phot_median)):\n",
    "                    clusters.at[index, \"ncluster\"] = clusternum\n",
    "                    clusters.at[i, \"neighbor_gids\"] = np.concatenate((clusters.at[i, \"neighbor_gids\"], clusters.at[index, \"neighbor_gids\"]), axis = 0) \n",
    "            clusternum += 1\n",
    "    \n",
    "    #Results\n",
    "    cluster_center = clusters.sort_values(by = ['ncluster','ultra_local_neighbor_mass'], ascending = [True, False]).groupby('ncluster').head(1).copy()\n",
    "    cluster_center_selected = cluster_center[np.logical_and.reduce((cluster_center.RA < maxRA, cluster_center.RA > minRA, cluster_center.DEC < maxDEC, cluster_center.DEC > minDEC))].copy()\n",
    "    \n",
    "    #Membership\n",
    "    membership = pd.DataFrame(cluster_center_selected.neighbor_gids.values)\n",
    "    membership_data = np.zeros((1, 5))\n",
    "    for i in range(0, len(membership)):\n",
    "        temp = np.stack(membership.values[i])[0]\n",
    "        membership_data = np.concatenate([membership_data, temp], axis = 0)\n",
    "    membershippd = pd.DataFrame(membership_data[1:], columns = [\"galaxy\", \"cluster\", \"galaxy_z\", \"cluster_z\", \"galaxy_z_std\"], dtype = float)\n",
    "    membershippd[\"z_dist\"] = np.abs(membershippd.galaxy_z - membershippd.cluster_z)\n",
    "    membershippd.sort_values(\"z_dist\", ascending = True, inplace = True)\n",
    "    membershippd.drop_duplicates(subset = \"galaxy\", inplace = True)\n",
    "    membershippd.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    iterrator3 = membershippd.copy()\n",
    "    membershippd[\"prob\"] = np.zeros(len(membershippd))\n",
    "    for i, row in iterrator3.iterrows():\n",
    "        x = row.galaxy_z\n",
    "        mu = row.cluster_z\n",
    "        std = row.galaxy_z_std\n",
    "        membershippd.at[i, \"prob\"] = 2*(1-norm.cdf(x = np.abs(x-mu), loc = 0, scale = std))\n",
    "    memberspd = membershippd[membershippd.prob > 0.0027].astype({\"galaxy\": \"int64\", \"cluster\": \"int64\"}).drop(columns = {\"z_dist\"})\n",
    "    \n",
    "    #Cleaning things up\n",
    "    cluster_center_selected[\"BRICKNAME\"] = cluster_center_selected[\"BRICKNAME\"].astype('|S80')\n",
    "    clusters_final = cluster_center_selected[[\"RA\", \"DEC\", \"z_phot_median\", \"z_phot_std\", \"mass\", \"RELEASE\", \"BRICKID\", \"OBJID\", \"MASKBITS\", \"gid\", \"neighbor_mass\", \"corr_local_neighbor_mass\", \"corr_ultra_local_neighbor_mass\", \"correction_factor\", \"neighbors\", \"local_neighbors\", \"ultra_local_neighbors\"]].copy()\n",
    "    clusters_final.columns = [\"RA_central\", \"DEC_central\", \"z_median_central\", \"z_std_central\", \"mass_central\", \"RELEASE\", \"BRICKID\", \"OBJID\", \"MASKBITS\", \"gid\", \"neighbor_mass\", \"local_neighbor_mass\", \"ultra_local_neighbor_mass\", \"correction_factor\", \"neighbors\", \"local_neighbors\", \"ultra_local_neighbors\"]\n",
    "    \n",
    "    return clusters_final, memberspd\n",
    "\n",
    "# @@ Cell 11\n",
    "pbar = display.ProgressBar(len(testing_centers))\n",
    "pbar.display()\n",
    "\n",
    "delayed_results = []\n",
    "\n",
    "#Remember to change testing_centers to table_of_centers\n",
    "for index, row in testing_centers[-1:].iterrows():\n",
    "    fits_data = fitsio.FITS(row.patch)\n",
    "    sweep = fits_data[1].read(columns=['RA', 'DEC'])\n",
    "    \n",
    "    maxx = max(sweep['RA'])\n",
    "    maxy = max(sweep['DEC'])\n",
    "    minx = min(sweep['RA'])\n",
    "    miny = min(sweep['DEC'])\n",
    "    \n",
    "    maxRA = max(sweep['RA'])\n",
    "    maxDEC = max(sweep['DEC'])\n",
    "    minRA = min(sweep['RA'])\n",
    "    minDEC = min(sweep['DEC'])\n",
    "    \n",
    "    list_of_imports = []\n",
    "    buffer = 0.285\n",
    "    #Neighbors:\n",
    "    distances, indices = nbrs.kneighbors([row[[\"mean_RA\", \"mean_DEC\"]]])\n",
    "    patches = table_of_centers_south.iloc[indices[0]]\n",
    "    for index2, row2 in patches.iterrows():\n",
    "        delayed_import = data_import(index2, row2)\n",
    "        list_of_imports.append(delayed_import)\n",
    "    \n",
    "    imports = dask.compute(*list_of_imports)\n",
    "    ra_dec = pd.concat(imports)\n",
    "    ra_dec = ra_dec[np.logical_and.reduce((ra_dec.RA < maxRA, ra_dec.RA > minRA, ra_dec.DEC < maxDEC, ra_dec.DEC > minDEC))].copy()\n",
    "    #Initial sample cuts\n",
    "    zmag=np.array(22.5-2.5*np.log10(ra_dec.FLUX_Z))\n",
    "    zmag[np.where(~np.isfinite(zmag))]=99.\n",
    "    #whgood=np.where(np.logical_and(zmag < 21,ra_dec.mass > 0 ))\n",
    "    isgood=np.logical_and(zmag < 21,ra_dec.mass > 0 )\n",
    "    ra_dec = ra_dec[isgood]\n",
    "    \n",
    "    #Further sample cuts\n",
    "    ra_dec = ra_dec[np.logical_or(ra_dec.MASKBITS == 0, ra_dec.MASKBITS == 4096)]\n",
    "    ra_dec = ra_dec[np.logical_or(np.logical_or(ra_dec.gaia_phot_g_mean_mag > 19, ra_dec.gaia_astrometric_excess_noise > 10**.5), ra_dec.gaia_astrometric_excess_noise==0)]\n",
    "    ra_dec[\"magR\"] = 22.5-2.5*np.log10(ra_dec.FLUX_R)\n",
    "    ra_dec[\"magZ\"] = 22.5-2.5*np.log10(ra_dec.FLUX_Z)\n",
    "    ra_dec[\"magW1\"] = 22.5-2.5*np.log10(ra_dec.FLUX_W1)\n",
    "    l_mask = (ra_dec.magR - ra_dec.magW1) > 1.8*(ra_dec.magR-ra_dec.magZ)-0.6\n",
    "    l_mask[~np.isfinite(l_mask)] = False\n",
    "    ra_dec = ra_dec[np.logical_and(22.5 - 2.5*np.log10(ra_dec.FLUX_Z)<21, ra_dec.z_phot_median>0.01)]\n",
    "    \n",
    "    #Coordinates\n",
    "    ra_dec[\"RA_r\"] = (np.pi/180)*ra_dec[\"RA\"]\n",
    "    ra_dec[\"DEC_r\"] = (np.pi/180)*ra_dec[\"DEC\"]\n",
    "    ra_dec[\"gid\"] = np.round(ra_dec.RA, 6)*10**16 + np.round(ra_dec.DEC + 90, 6)*10**6\n",
    "    print(len(ra_dec))\n",
    "    \n",
    "    #Oversampling\n",
    "    ra_dec.reset_index(inplace = True, drop = True)\n",
    "    oversample = 30\n",
    "    over = np.array([ra_dec.z_phot_median.values]).T*np.ones((len(ra_dec), oversample))\n",
    "    sigma = np.array([ra_dec.z_phot_std.values]).T*np.ones((len(ra_dec), oversample))\n",
    "    random = np.random.normal(loc = 0, scale = 1, size = (len(ra_dec), oversample))\n",
    "    gauss = over + sigma*random\n",
    "    ra_dec[\"gauss_z\"] = pd.Series(list(gauss))\n",
    "    \n",
    "    #Coordinate transform to prevent zeros\n",
    "    ra_dec[\"y\"] = ra_dec[\"DEC_r\"] - np.mean(ra_dec[\"DEC_r\"]) + 50\n",
    "    ra_dec[\"x\"] = (ra_dec[\"RA_r\"] - np.mean(ra_dec[\"RA_r\"]))*np.cos(ra_dec[\"DEC_r\"]) + 50\n",
    "    #ra_dec = ra_dec[ra_dec.z_phot_median < 1.5].copy()\n",
    "    #Creating array for indexing\n",
    "    indexable = ra_dec[[\"z_phot_median\", \"x\", \"y\", \"mass\", \"gauss_z\", \"gid\", \"z_phot_std\"]].values.copy()\n",
    "    #dindexable = dask.delayed([indexable])\n",
    "    \n",
    "    #Creating massive sample\n",
    "    massive_sample = ra_dec[ra_dec.mass > 11.2].copy()\n",
    "    massive_sample[\"neighbor_mass\"] = np.zeros(len(massive_sample))\n",
    "    massive_sample[\"local_neighbor_mass\"] = np.zeros(len(massive_sample))\n",
    "    massive_sample[\"ultra_local_neighbor_mass\"] = np.zeros(len(massive_sample))\n",
    "    massive_sample[\"corrected_neighbor_mass\"] = np.zeros(len(massive_sample))\n",
    "    massive_sample[\"neighbors\"] = np.zeros(len(massive_sample))\n",
    "    massive_sample[\"local_neighbors\"] = np.zeros(len(massive_sample))\n",
    "    massive_sample[\"ultra_local_neighbors\"] = np.zeros(len(massive_sample))\n",
    "    massive_sample[\"neighbor_gids\"] = np.empty((len(massive_sample)), dtype = \"object\")\n",
    "    massive_sample[\"z_average_no_wt\"] = np.zeros(len(massive_sample))\n",
    "    massive_sample[\"z_average_prob\"] = np.zeros(len(massive_sample))\n",
    "    massive_sample[\"z_average_mass_prob\"] = np.zeros(len(massive_sample))\n",
    "    massive_sample[\"z_std_no_wt\"] = np.zeros(len(massive_sample))\n",
    "    massive_sample[\"z_std_prob\"] = np.zeros(len(massive_sample))\n",
    "    massive_sample[\"z_std_mass_prob\"] = np.zeros(len(massive_sample))\n",
    "    massive_sample.reset_index(inplace=True, drop = True)\n",
    "    #dmassive_sample = dask.delayed([massive_sample])\n",
    "    \n",
    "    cluster_centrals, cluster_members = cluster_finder(massive_sample, indexable, maxRA, maxDEC, minRA, minDEC)\n",
    "    \"\"\"delayed_results.append(delayed_result)\n",
    "    \n",
    "    if (index)%3 == 0:\n",
    "        results = dask.compute(*delayed_results)\n",
    "        if len(results)>1:\n",
    "            cluster_centrals = pd.concat([select[0] for select in results])\n",
    "            cluster_members = pd.concat([select[1] for select in results])\n",
    "        else:\n",
    "            cluster_centrals = results[0][0]\n",
    "            cluster_members = results[0][1]\n",
    "        print(len(cluster_centrals), len(cluster_members))\n",
    "        cc = Table.from_pandas(cluster_centrals)\n",
    "        cm = Table.from_pandas(cluster_members)\n",
    "        cc.write(f'test_table_c{index}.fits', format = 'fits')\n",
    "        cm.write(f'test_table_m{index}.fits', format = 'fits')\n",
    "        delayed_results = []\n",
    "    \n",
    "    if index+1 == len(testing_centers):\n",
    "        results = dask.compute(*delayed_results)\n",
    "        if len(results)>1:\n",
    "            cluster_centrals = pd.concat([select[0] for select in results])\n",
    "            cluster_members = pd.concat([select[1] for select in results])\n",
    "        else:\n",
    "            cluster_centrals = results[0][0]\n",
    "            cluster_members = results[0][1]\n",
    "        print(len(cluster_centrals), len(cluster_members))\n",
    "        cc = Table.from_pandas(cluster_centrals)\n",
    "        cm = Table.from_pandas(cluster_members)\n",
    "        cc.write(f'test_table_c{index}.fits', format = 'fits')\n",
    "        cm.write(f'test_table_m{index}.fits', format = 'fits')\"\"\"\n",
    "    \n",
    "    pbar.progress = index + 1\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
